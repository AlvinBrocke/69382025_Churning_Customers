# -*- coding: utf-8 -*-
"""Assignment 3: Churning Customers in a Telecoms Company

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vpPBSOu__92Hss81cnK-Zue8LiEi8xtL
"""

!pip install scikeras

import pickle
import pandas as pd
import numpy as np
import scikeras
import tensorflow as tf
import seaborn as sns
from sklearn import metrics
from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from matplotlib import pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report
from imblearn.over_sampling import RandomOverSampler
from sklearn.neural_network import MLPClassifier

from sklearn.datasets import make_classification

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/CustomerChurn_dataset.csv")

df

"""**1. Data Preparation & Cleaning (EDA)**"""

df.info()

df.head()

"""OneHot features: The Rest
Label Encoding: Yes and No
"""

df.describe()

print(df.isnull().sum())
df.fillna(df.mean(), inplace=True)

# Converting the TotalCharges column to numeric
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors = 'coerce')
df['TotalCharges'].fillna(0, inplace=True)

df.info(verbose=True)

# Dropping irrelevant columns
df = df.drop(columns=['customerID'], axis=1)
df = df.dropna()

df.info()

# Extracting the numeric and data
numeric = df.select_dtypes(include=['number'])
numeric

# Distribution of Numeric Variables
numeric.hist(figsize=(12, 10), bins=20)
plt.show()

# Extracting the numeric and data
categorical = df.select_dtypes(include=['object'])
categorical

#Label Encoding
label_encoding_features = categorical[['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']]
# label_encoding_features = categorical

label_encoders = {}

label_encoded_df = pd.DataFrame()

for col in label_encoding_features.columns:
    label_encoders[col] = LabelEncoder()
    label_encoded_df[col] = label_encoders[col].fit_transform(label_encoding_features[col])

print(label_encoded_df)

# One Hot Encoding
one_hot_features = categorical[['MultipleLines', 'InternetService', 'OnlineSecurity',
                    'OnlineBackup', 'DeviceProtection', 'TechSupport',
                    'StreamingTV', 'StreamingMovies', 'Contract', 'PaymentMethod']]

# one_hot_features = categorical.drop('Churn', axis=1)

one_hot_df = pd.get_dummies(one_hot_features, columns=one_hot_features.columns)

print(one_hot_df)

new_df = pd.concat([numeric, label_encoded_df, one_hot_df], axis=1)
# new_df = pd.concat([numeric, label_encoded_df], axis=1)
# new_df = pd.concat([numeric, one_hot_df], axis=1)

new_df.info(verbose=True)

"""**2. Feature Selection & Importance**"""

# Scaling the features for training and testing
scaler = StandardScaler()
X_data = new_df.drop('Churn', axis=1)
X_scaled = scaler.fit_transform(X_data)
X_scaled = pd.DataFrame(X_scaled, columns=X_data.columns)
print(X_scaled)

#Splitting the data for Feature Selection
X = X_scaled
y = new_df['Churn']

# Using Random Forest Classifier for Feature Selection
rf_classifier = RandomForestClassifier()
rf_classifier.fit(X, y)

feature_importances = rf_classifier.feature_importances_

feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})

feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

print(feature_importance_df)

# Features and Importance scores
features = feature_importance_df['Feature']
importance_scores = feature_importance_df['Importance']

# Create a bar plot for all feature importances
plt.figure(figsize=(6, 8))
plt.barh(features, importance_scores, color='blue')
plt.xlabel('Importance Scores')
plt.ylabel('Features')
plt.title('Feature Importance')
plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility
plt.tight_layout()
plt.show()

# Distribution of Churn
import plotly.express as px

target = new_df["Churn"].value_counts().to_frame().reset_index()
target = target.rename(columns={'index': 'Category', 'Churn': 'Count'})

fig = px.pie(target, values='Count', names='Category', color_discrete_sequence=["blue", "red"],
             title='Distribution of Churn')

fig.show()

# Average Tenure by Churn
plt.figure(figsize=(8, 6))
sns.barplot(x='Churn', y='tenure', data=new_df, palette='viridis')
plt.xlabel('Churn')
plt.ylabel('Average Tenure')
plt.title('Comparison of Average Tenure for Churn Categories')
plt.show()

# Gender Distribution of Churn
plt.figure(figsize=(8, 6))
sns.countplot(x='gender', hue='Churn', data=new_df, palette='viridis')
plt.xlabel('Gender')
plt.ylabel('Count')
plt.title('Churn Comparison by Gender')
plt.legend(title='Churn', loc='upper right', labels=['No Churn', 'Churn'])
plt.show()

plt.figure(figsize=(10, 6))
sns.histplot(data=new_df, x='MonthlyCharges', hue='Churn', bins=20, kde=True, palette='viridis')
plt.xlabel('Monthly Charges')
plt.ylabel('Frequency')
plt.title('Distribution of Monthly Charges for Churn and No Churn')
plt.show()

# Filter out columns with importance less than 0.010
selected_features = feature_importance_df[feature_importance_df['Importance'] >= 0.02]['Feature'].tolist()
print(len(selected_features))
print(selected_features)

"""**3. Training the Multi-Layer Perceptron**"""

sc = StandardScaler()
X_data = pd.DataFrame(new_df[selected_features], columns = selected_features)
X = sc.fit_transform(X_data)
y = new_df['Churn']

print(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Keras Functional API model
input_layer = Input(shape=(X_train.shape[1],))
hidden_layer_1 = Dense(32, activation='relu')(input_layer)
hidden_layer_2 = Dense(24, activation='relu')(hidden_layer_1)
hidden_layer_3 = Dense(12, activation='relu')(hidden_layer_2)
output_layer = Dense(1, activation='sigmoid')(hidden_layer_3)

model = Model(inputs=input_layer, outputs=output_layer)

model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model and save the training history
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))

_, accuracy = model.evaluate(X_train, y_train)
accuracy*100

loss, accuracy = model.evaluate(X_test, y_test)
print(f'Test Loss: {loss:.4f}')
print(f'Test Accuracy: {accuracy*100:.4f}')

# Plot training history
plt.figure(figsize=(12, 6))

# Plot Training & Validation Loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Plot Training & Validation Accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.show()

# Predictions on the test set
y_pred = model.predict(X_test)

# Threshold predictions for binary classification
y_pred_binary = (y_pred > 0.5).astype(int)

# Evaluate accuracy and AUC score
accuracy = accuracy_score(y_test, y_pred_binary)
auc_score = roc_auc_score(y_test, y_pred)

print("Accuracy:", accuracy)
print("AUC Score:", auc_score)

"""# **5.GridSearchCV and Cross-Validation**

---


"""

# Define the MLP model using the Functional API
def create_mlp_model(hidden_layer_sizes=(100,), activation='relu', solver='adam'):
    inputs = Input(shape=(X_train.shape[1],))
    x = Dense(hidden_layer_sizes[0], activation=activation)(inputs)
    for units in hidden_layer_sizes[1:]:
        x = Dense(units, activation=activation)(x)
    outputs = Dense(1, activation='sigmoid')(x)
    model = Model(inputs=inputs, outputs=outputs)
    model.compile(optimizer=solver, loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Create the MLP model
mlp_model = MLPClassifier()

# Define the hyperparameter grid to search
param_grid = {
    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],
    'activation': ['relu', 'tanh'],
    'solver': ['adam', 'sgd'],
}

# Create GridSearchCV object
grid_search = GridSearchCV(mlp_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# Fit the model using GridSearchCV
grid_search.fit(X_train, y_train)

# Get the best parameters from the grid search
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Train the model with the best hyperparameters
best_model = MLPClassifier(**best_params)
best_model.fit(X_train, y_train)

# Predictions on the test set
y_pred = best_model.predict(X_test)
y_pred_proba = best_model.predict_proba(X_test)[:, 1]

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
auc_score = roc_auc_score(y_test, y_pred_proba)

print("Accuracy:", accuracy)
print("AUC Score:", auc_score)

import pickle
# Specifying the file name for scaler
pickle_filename = "best_churn_model.pkl"

# Saving the scaler to the file
with open(pickle_filename, 'wb') as model_file:
    pickle.dump(best_model, model_file)

# Specifying the file name for scaler
pickle_filename = "scaler.pkl"

# Saving the scaler to the file
with open(pickle_filename, 'wb') as model_file:
    pickle.dump(sc, model_file)